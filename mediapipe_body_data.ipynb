{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35Fx71KHBGYJ",
    "outputId": "6a5a5bb9-c9f8-421a-8f79-94548bb45ef2"
   },
   "outputs": [],
   "source": [
    "# !pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "import cv2\n",
    "# from google.colab.patches import cv2_imshow\n",
    "import numpy as np\n",
    "from time import time\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "id": "IzOQI5yFBjfv"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def calculateAngle(landmark1, landmark2, landmark3):\n",
    "    x1, y1, _ = landmark1\n",
    "    x2, y2, _ = landmark2\n",
    "    x3, y3, _ = landmark3\n",
    "\n",
    "    angle = math.degrees(math.atan2(y3 - y2, x3 - x2) - math.atan2(y1 - y2, x1 - x2))\n",
    "    \n",
    "    if angle < 0:\n",
    "        # angle += 360\n",
    "        angle *= -1\n",
    "    \n",
    "    return angle"
   ],
   "metadata": {
    "id": "AhSzrHOjRIsn"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def ccw(A,B,C):\n",
    "\n",
    "    a_x, a_y, _ = A\n",
    "    b_x, b_y, _ = B\n",
    "    c_x, c_y, _ = C\n",
    "\n",
    "    return (c_y-a_y) * (b_x-a_x) > (b_y-a_y) * (c_x-a_x)\n",
    "\n",
    "def isCrossingVectors(vec1_point1, vec1_point2, \n",
    "                      vec2_point1, vec2_point2):\n",
    "\n",
    "    return ccw(vec1_point1,vec2_point1,vec2_point2) != ccw(vec1_point2,vec2_point1,vec2_point2) and \\\n",
    "              ccw(vec1_point1,vec1_point2,vec2_point1) != ccw(vec1_point1,vec1_point2,vec2_point2)"
   ],
   "metadata": {
    "id": "T4Dsay7LtAEX"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def getPoseAngle(landmarks):\n",
    "\n",
    "  if landmarks:\n",
    "    \n",
    "    left_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "\n",
    "    right_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])\n",
    " \n",
    "    left_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                            landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n",
    "\n",
    "    right_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                              landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                              landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "\n",
    "    left_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                        landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "                                        landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "\n",
    "    right_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "    \n",
    "    right_hip_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value])\n",
    "    \n",
    "    left_hip_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                          landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value])\n",
    "\n",
    "    return {'left_elbow_angle': left_elbow_angle,\n",
    "            'right_elbow_angle': right_elbow_angle,\n",
    "            'left_shoulder_angle': left_shoulder_angle,\n",
    "            'right_shoulder_angle': right_shoulder_angle,\n",
    "            'left_knee_angle': left_knee_angle,\n",
    "            'right_knee_angle': right_knee_angle,\n",
    "            'right_hip_angle': right_hip_angle,\n",
    "            'left_hip_angle': left_hip_angle}"
   ],
   "metadata": {
    "id": "5J9ynBEkam4P"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def getPoseCrossing(landmarks):\n",
    "\n",
    "  if landmarks:\n",
    "\n",
    "    crossing_forearm = isCrossingVectors(landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "\n",
    "    crossing_shin = isCrossingVectors(landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "\n",
    "    crossing_hip = isCrossingVectors(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value])\n",
    "\n",
    "    crossing_ship_hip = isCrossingVectors(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value]) or \\\n",
    "                        isCrossingVectors(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "                                landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "\n",
    "    return {'crossing_forearm': crossing_forearm,\n",
    "            'crossing_shin': crossing_shin,\n",
    "            'crossing_hip': crossing_hip,\n",
    "            'crossing_ship_hip': crossing_ship_hip}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "DESIRED_HEIGHT = 800\n",
    "DESIRED_WIDTH = 800\n",
    "\n",
    "def resize_and_show(image):\n",
    "  h, w = image.shape[:2]\n",
    "  if h < w:\n",
    "    img = cv2.resize(image, (DESIRED_WIDTH, math.floor(h/(w/DESIRED_WIDTH))))\n",
    "  else:\n",
    "    img = cv2.resize(image, (math.floor(w/(h/DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
    "  # cv2_imshow(img)\n",
    "\n",
    "# # Read images with OpenCV.\n",
    "# images = {name: cv2.imread(name) for name in uploaded.keys()}\n",
    "#\n",
    "# for name, image in images.items():\n",
    "#   resize_and_show(image)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "6MmV6er1K4z4",
    "outputId": "cd9197de-ab30-4272-ee86-ec70b273a3d3"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3)\n",
    "mp_pose_drawing = mp.solutions.drawing_utils"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.6)\n",
    "mp_hands_drawing = mp.solutions.drawing_utils"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def detectPose(image, pose, display2D=False, display3D=False):\n",
    "\n",
    "    copy_image = image.copy()\n",
    "\n",
    "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(imageRGB)\n",
    "    height, width, _ = image.shape\n",
    "    landmarks = []\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "\n",
    "        mp_pose_drawing.draw_landmarks(image=copy_image,\n",
    "                                       landmark_list=results.pose_landmarks,\n",
    "                                       connections=mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            landmarks.append((int(landmark.x * width), int(landmark.y * height), (landmark.z * width)))\n",
    "\n",
    "    if display2D:\n",
    "        plt.figure(figsize=[22,22])\n",
    "        plt.subplot(122);plt.imshow(copy_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "\n",
    "    if display3D:\n",
    "        mp_pose_drawing.plot_landmarks(results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    return copy_image, landmarks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def detectHands(image, hands, display2D=False, display3D=False):\n",
    "\n",
    "    copy_image = cv2.flip(image.copy(), 1)\n",
    "\n",
    "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(cv2.flip(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), 1))\n",
    "    height, width, _ = image.shape\n",
    "    landmarks = []\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    # if results.multi_hand_landmarks:\n",
    "    #\n",
    "    #     for hand_landmarks in results.multi_hand_landmarks:\n",
    "    #\n",
    "    #     # hand_name = r_hands.multi_handedness[i].classification[0].label.lower()\n",
    "    #     #\n",
    "    #     # result[f'{hand_name}_'+'thumb_tip'] = { 'x': hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].x * image_width,\n",
    "    #     #                                         'y': hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].y * image_hight }\n",
    "    #     # result[f'{hand_name}_'+'index_finger_tip'] = { 'x': hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width,\n",
    "    #     #                                                 'y': hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_hight }\n",
    "    #     # result[f'{hand_name}_'+'middle_finger_tip'] = { 'x': hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].x * image_width,\n",
    "    #     #                                                 'y': hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].y * image_hight }\n",
    "    #     # result[f'{hand_name}_'+'ring_finger_tip'] = { 'x': hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP].x * image_width,\n",
    "    #     #                                               'y': hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP].y * image_hight}\n",
    "    #     # result[f'{hand_name}_'+'pinky_tip'] = { 'x': hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP].x * image_width,\n",
    "    #     #                                         'y': hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP].y * image_hight}\n",
    "    #     # i += 1\n",
    "    #\n",
    "    #         mp_hands_drawing.draw_landmarks(image=copy_image,\n",
    "    #                                         landmark_list=hand_landmarks,\n",
    "    #                                         connections=mp_hands.HAND_CONNECTIONS)\n",
    "    #\n",
    "    #         for landmark in results.pose_landmarks.landmark:\n",
    "    #             landmarks.append((int(landmark.x * width), int(landmark.y * height), (landmark.z * width)))\n",
    "\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "      for hand_landmarks in results.multi_hand_landmarks:\n",
    "        mp_hands_drawing.draw_landmarks(\n",
    "            copy_image,\n",
    "            hand_landmarks,\n",
    "            mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    if display2D:\n",
    "        resize_and_show(cv2.flip(image, 1))\n",
    "\n",
    "      # if display3D:\n",
    "          # for name, image in images.items():\n",
    "          #   if not r_hands.multi_hand_world_landmarks:\n",
    "          #     continue\n",
    "          #   for hand_world_landmarks in r_hands.multi_hand_world_landmarks:\n",
    "          #     mp_hands_drawing.plot_landmarks(hand_world_landmarks, mp_hands.HAND_CONNECTIONS, azimuth=5)\n",
    "\n",
    "    return cv2.flip(copy_image, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def classifyPose(landmarks, output_image, display=False):\n",
    "\n",
    "    label = 'Unknown Pose'\n",
    "    color = (0, 0, 255)\n",
    "\n",
    "    angels = getPoseAngle(landmarks)\n",
    "    crossings = getPoseCrossing(landmarks)\n",
    "\n",
    "    left_elbow_angle = angels['left_elbow_angle']\n",
    "    right_elbow_angle = angels['right_elbow_angle']\n",
    "    left_shoulder_angle = angels['left_shoulder_angle']\n",
    "    right_shoulder_angle = angels['right_shoulder_angle']\n",
    "    left_knee_angle = angels['left_knee_angle']\n",
    "    right_knee_angle = angels['right_knee_angle']\n",
    "\n",
    "    crossing_forearm = crossings['crossing_forearm']\n",
    "    crossing_shin = crossings['crossing_shin']\n",
    "    crossing_hip = crossings['crossing_hip']\n",
    "    crossing_ship_hip = crossings['crossing_ship_hip']\n",
    "\n",
    "    if crossing_forearm and \\\n",
    "            (left_elbow_angle > 25 and left_elbow_angle < 65) and \\\n",
    "            (right_elbow_angle > 25 and right_elbow_angle < 65) and \\\n",
    "            (left_shoulder_angle > 0 and left_shoulder_angle < 25) and \\\n",
    "            (right_shoulder_angle > 0 and right_shoulder_angle < 25):\n",
    "        label = 'Negative'\n",
    "\n",
    "    if label != 'Unknown Pose':\n",
    "        color = (0, 255, 0)\n",
    "\n",
    "    cv2.putText(output_image, label, (10, 30),cv2.FONT_HERSHEY_PLAIN, 2, color, 2)\n",
    "\n",
    "    if display:\n",
    "        plt.figure(figsize=[10,10])\n",
    "        plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "\n",
    "    else:\n",
    "        return output_image, label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "#\n",
    "# uploaded = files.upload()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# output_image, landmarks = detectPose(image, pose, False, False)\n",
    "#\n",
    "# angels = getPoseAngle(landmarks)\n",
    "# crossings = getPoseCrossing(landmarks)\n",
    "# res = getHandsData(output_image, hands, True, False)\n",
    "#\n",
    "# res, angels, crossings"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 845
    },
    "id": "K-2zW2LJfZnJ",
    "outputId": "7476131d-6796-4fe6-eac5-04661cda512a"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# classifyPose(landmarks, output_image, display=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "QjvvEJwEZxvA",
    "outputId": "b303fd3c-9bee-4f6b-a8b7-b26d4cd35a76"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Setup Pose function for video.\n",
    "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.7)\n",
    "hands_video = mp_hands.Hands(static_image_mode=False, min_detection_confidence=0.6, max_num_hands=2)\n",
    "\n",
    "# Initialize the VideoCapture object to read from the webcam.\n",
    "camera_video = cv2.VideoCapture(0)\n",
    "camera_video.set(3,1280)\n",
    "camera_video.set(4,960)\n",
    "\n",
    "# Initialize a resizable window.\n",
    "cv2.namedWindow('Emotional state detector', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Iterate until the webcam is accessed successfully.\n",
    "while camera_video.isOpened():\n",
    "    \n",
    "    # Read a frame.\n",
    "    ok, frame = camera_video.read()\n",
    "    \n",
    "    # Check if frame is not read properly.\n",
    "    if not ok:\n",
    "        \n",
    "        # Continue to the next iteration to read the next frame and ignore the empty camera frame.\n",
    "        continue\n",
    "    \n",
    "    # Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Get the width and height of the frame\n",
    "    frame_height, frame_width, _ =  frame.shape\n",
    "    \n",
    "    # Resize the frame while keeping the aspect ratio.\n",
    "    frame = cv2.resize(frame, (int(frame_width * (640 / frame_height)), 640))\n",
    "    \n",
    "    # Perform Pose landmark detection.\n",
    "    frame = detectHands(frame, hands_video)\n",
    "    frame, landmarks = detectPose(frame, pose_video)\n",
    "\n",
    "    # Check if the landmarks are detected.\n",
    "    if landmarks:\n",
    "        \n",
    "        # Perform the Pose Classification.\n",
    "        frame, _ = classifyPose(landmarks, frame)\n",
    "    \n",
    "    # Display the frame.\n",
    "    cv2.imshow('Emotional state detector', frame)\n",
    "    \n",
    "    # Wait until a key is pressed.\n",
    "    # Retreive the ASCII code of the key pressed\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # Check if 'ESC' is pressed.\n",
    "    if(k == 27):\n",
    "        \n",
    "        # Break the loop.\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture object and close the windows.\n",
    "camera_video.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "id": "UmwwpMRsEMZS"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
